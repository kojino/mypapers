# mypapers
List of my favorite papers.

## Deep Learning

### Adversarial Examples
* [x] [Szegedy et al., 2014: Intriguing properties of neural networks](https://arxiv.org/pdf/1312.6199.pdf),
the first paper to introduce adversarial examples
* [x] [Moosavi-Dezfooli et al., 2016: DeepFool: a simple and accurate method to fool deep neural netwoks](https://arxiv.org/pdf/1511.04599.pdf), develops gradient descent like and Newton's method like ways of finding adversarial examples
* [ ] [Carlini et al., 2017: Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods](https://arxiv.org/abs/1705.07263)

#### Transferability
* [ ] [Tramer et al., 2017: The Space of Transferable Adversarial Examples](https://arxiv.org/abs/1704.03453)
* [x] [Mohsen et al., 2016: Universal adversarial perturbations](https://arxiv.org/abs/1610.08401), aggregate minimal perturbations from multiple classifiers, quite empirical
* [ ] [Fawzi et al., 2018: Adversarial vulnerability for any classifier](https://arxiv.org/abs/1802.08686)

### GAN
* [x] [Goodfellow et al., 2014: Generative Adversarial Nets](https://arxiv.org/pdf/1406.2661.pdf), the first paper to introduce GAN

#### WGAN
* [x] [Arjovsky et al., 2017: Wasserstein GAN](https://arxiv.org/abs/1701.07875), use EM distance instead of JS divergence for more stable GAN training

#### Equilibrium Convergence
* [ ] [Daskalakis et al., 2017: Training GANs with Optimism](https://arxiv.org/abs/1711.00141)
* [ ] [Grnarova et al., 2017: An Online Learning Approach to Generative Adversarial Networks](https://arxiv.org/abs/1706.03269)

### DP
* [ ] [Abadi et al., 2016: Deep Learning with Differential Privacy](https://arxiv.org/abs/1607.00133)
* [ ] [Papernot et al., 2017: Semi-supervised Knowledge Transfer for Deep Learning from Private Training Data](https://arxiv.org/abs/1610.05755)

### Understanding Deep Learning
* [ ] [Koh et al., 2017: Understanding Black-box Predictions via Influence Functions](https://arxiv.org/abs/1703.04730)
* [ ] [Zhang et al., 2018: Visual Interpretability for Deep Learning: a Survey](https://arxiv.org/abs/1802.00614)
* [ ] [Narayanan et al., 2018: How do Humans Understand Explanations from Machine Learning Systems? An Evaluation of the Human-Interpretability of Explanation](https://arxiv.org/abs/1802.00682?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=piqcy)

### Generalization
* [ ] [Zhang et al., 2016: Understanding deep learning requires rethinking generalization](https://arxiv.org/abs/1611.03530)


## EconCS
### Strategic Classification
* [ ] [Hardt et al., 2015: Strategic Classification](https://arxiv.org/abs/1506.06980)
